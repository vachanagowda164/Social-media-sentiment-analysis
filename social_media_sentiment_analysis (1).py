# -*- coding: utf-8 -*-
"""Social_media_sentiment_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JCtiWKDCVYT7EeWiwMbyR_zFq4oTaPyI

SOCIAL MEDIA SENTIMENT ANALYSIS

Sentiment Analysis is the NLP technique that performs on the text to determine whether the author’s intentions towards a particular topic, product, etc. are positive and negative.
"""

# Commented out IPython magic to ensure Python compatibility.
# Import the libraries 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import string
import nltk
import warnings 
warnings.filterwarnings("ignore", category=DeprecationWarning)
# %matplotlib inline

"""Data Preprocessing"""

#dropping the tweets that has neutral sentiment
df = pd.read_csv('Tweets.csv')
df = df[df['airline_sentiment'] != 'neutral']

df=df[['text','airline_sentiment']]
df.head(5) 
# shuffle the df and pick first 5

# Removing stopwords from text
nltk.download('stopwords')
from nltk.corpus import stopwords
stop=set(stopwords.words("english"))
print(stop)

df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
df

# Removing words which have length of 3 (ex:is,are,I)
df['text'] = df['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3 ]))
df

"""Removing Punctuation, Numbers, and Special Characters

Punctuation, numbers and special characters do not help much. It is better to remove them from the text. Here we will replace everything except characters and hashtags with spaces.
"""

# Removing special characters and symbols
df['text'] = df['text'].str.replace("[^a-zA-Z#]"," ")
df

"""Tokenization

It is breaking the raw text into small chunks. Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words
"""

tokenized_text1= df['text'].apply(lambda x: x.split())

"""Stemming(imported from the NLTK package)

Stemming is a rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word.
"""

# Splitting sentence into words and extrate the base form of words
from nltk import PorterStemmer
ps = PorterStemmer()
tokenized_text1 = tokenized_text1.apply(lambda x: [ps.stem(i) for i in x])
tokenized_text1

"""Vectorization

Word vectorization is a methodology in NLP to map words or phrases from vocabulary to a corresponding vector of real numbers which used to find word predictions, word similarities/semantics. The process of converting words into numbers are called Vectorization
"""

# Coverting words to vector for comparison with input data
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=1000)
vectors = vectorizer.fit_transform(df['text'])
words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())
words_df.head()

X = words_df
y = df['airline_sentiment']

"""Training the model using the machine learing methods such as Logistic regression,Support vector machines,etc."""

# spliting dataset for training and testing
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,y,random_state=1,test_size=0.1,shuffle=False)

# Training the model using Logistic Regression
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)
logreg.fit(x_train, y_train)
prediction_linear = logreg.predict(vectors)
logreg.score(x_test,y_test)#testing the accuracy of Logistic Regression model

#Training the model using SVM
from sklearn import svm
from sklearn.metrics import classification_report
# Perform classification with SVM, kernel=linear
clf_svm = svm.SVC(kernel='linear')
clf_svm.fit(vectors, df['airline_sentiment'])
prediction_linear1 = clf_svm.predict(vectors)
clf_svm.score(x_test,y_test)#testing the accuracy of SVM model

# Results
report = classification_report(df['airline_sentiment'], prediction_linear1, output_dict=True)
print('positive: ', report['positive'])
print('negative: ', report['negative'])

# function built for prediction of a owrd or sentence
def predict_sentiment():
    review=input()
    review_vector = vectorizer.transform([review])
    print(clf_svm.predict(review_vector))#accuracy of svm model is more

# Predicting any data 
predict_sentiment()

